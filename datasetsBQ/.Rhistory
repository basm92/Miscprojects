library(lubridate)
library(glogis)
library(gridExtra)
library(kableExtra)
x <- c("ggmap", "rgdal", "rgeos", "maptools", "tmap")
lapply(x, library, character.only = TRUE)
#Ici, il faut choisir la data à laquelle on va construire la carte.
datum <- Sys.Date() -1
#Importer les données françaises via cet URL:
France <- read.csv("https://www.data.gouv.fr/fr/datasets/r/fa9b8fc8-35d5-4e24-90eb-9abe586b0fa5",header = TRUE, check.names = F)
France <- France %>%
pivot_longer(2:ncol(France),
names_to = "departement",
values_to = "montant") %>%
mutate(Date = ymd(Date))
write.csv(France, "../Data/France.csv")
Belgium <- read_html("https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Belgium") %>%
html_nodes(".wikitable") %>%
html_table(fill = TRUE) %>%
data.frame() %>%
select(1,3,5,7)
a <- as.numeric(nrow(Belgium))
Belgium <- Belgium[-c(1,(a),(a-1)),] %>%
mutate(Date = ymd(Date))
colnames(Belgium) <- c("Date", "BE2", "BE1", "BE3")
Belgium <- Belgium %>%
pivot_longer(2:4, names_to = "NUTS_CODE", values_to = "montant")
write.csv(Belgium, "../Data/Belgique.csv")
#Importer les données néerlandaises va un peu plus difficilement: on va garder la date dans une colonne séparée:
Netherlands <- read_html("https://www.rivm.nl/coronavirus-kaart-van-nederland") %>%
html_nodes("#csvData") %>%
html_text() %>%
read_lines() %>%
str_split(";") %>%
unlist()
Netherlands <- Netherlands[-1] %>%
matrix(ncol = 5, byrow = TRUE)
Netherlands <- Netherlands[-(1:2),] %>%
as.data.frame()
date <- read_html("https://www.rivm.nl/coronavirus-kaart-van-nederland") %>%
html_nodes('.with-background > p:nth-child(2)') %>%
html_text() %>%
str_extract("[0-9]{2}\\s[a-z]{1,}\\s[0-9]{4}")
colnames(Netherlands) <- c("numero", "municipalite", "montant", "habitants", "montantparhabitant")
Netherlands <- data.frame(Netherlands, Date = date) %>%
filter(municipalite != "")
write.csv(Netherlands, file = paste("../Data/","netherlands_",date,".csv", sep = ""))
files <- list.files("../Data")
files <- files[grepl("netherlands(.+)", files)]
key <- NULL
Netherlands <- NULL
for (i in files) {
key <- read.csv(paste("../Data/",i, sep = "")) %>%
select(-1)
Netherlands <- rbind(Netherlands, key)
}
Before <- read_excel("../Data/corona_04032020tm16032020.xlsx", sheet = 2)
Before <- Before[!is.na(Before$Gemnr),] %>%
pivot_longer(3:ncol(Before), names_to = "Date", values_to = "montant") %>%
mutate(Date = dmy(str_replace(Date, "Aantal", "")))
colnames(Before) <- c("numero", "municipalite", "Date", "montant")
#Municipalites par province
municipalites <- read_html("https://www.metatopos.eu/Gemtab.php") %>%
html_nodes("section.dikkerand:nth-child(3) > article:nth-child(1) > table:nth-child(2)") %>%
html_table(fill = TRUE, header = TRUE) %>%
data.frame()
#municipalites par nl1 nl2 nl3 nl4
NL1 <- read_html("https://www.regioatlas.nl/indelingen/indelingen_indeling/t/nuts_1_regio_s_landsdelen") %>%
html_nodes("#noord_nederland > div:nth-child(3) > ul:nth-child(2)") %>%
html_text(trim = TRUE) %>%
read_lines() %>%
str_replace_all("\t[\\s]{0,}","")
NL2 <- read_html("https://www.regioatlas.nl/indelingen/indelingen_indeling/t/nuts_1_regio_s_landsdelen") %>%
html_nodes("#oost_nederland > div:nth-child(3) > ul:nth-child(2)") %>%
html_text(trim = TRUE) %>%
read_lines() %>%
str_replace_all("\t[\\s]{0,}","")
NL3 <- read_html("https://www.regioatlas.nl/indelingen/indelingen_indeling/t/nuts_1_regio_s_landsdelen") %>%
html_nodes("#west_nederland > div:nth-child(3) > ul:nth-child(2)") %>%
html_text(trim = TRUE) %>%
read_lines() %>%
str_replace_all("\t[\\s]{0,}","")
NL4 <- read_html("https://www.regioatlas.nl/indelingen/indelingen_indeling/t/nuts_1_regio_s_landsdelen") %>%
html_nodes("#zuid_nederland > div:nth-child(3) > ul:nth-child(2)") %>%
html_text(trim = TRUE) %>%
read_lines() %>%
str_replace_all("\t[\\s]{0,}","")
NUTSlvl1 <-
rbind(
data.frame(municipalite = NL1, NUTS = "NL1"),
data.frame(municipalite = NL2, NUTS = "NL2"),
data.frame(municipalite = NL3, NUTS = "NL3"),
data.frame(municipalite = NL4, NUTS = "NL4")
)
Netherlands <- merge(Netherlands, NUTSlvl1)
Netherlands <- Netherlands %>%
group_by(NUTS, Date) %>%
summarise(montant = sum(montant)) %>%
mutate(Date = dmy(Date))
Before <- Before %>%
merge(NUTSlvl1) %>%
mutate(montant = as.numeric(montant)) %>%
group_by(NUTS, Date) %>%
summarise(montant = sum(montant))
Netherlands <- rbind(Netherlands, Before)
Belgium <- Belgium %>%
mutate(montant = as.numeric(montant)) %>%
group_by(NUTS_CODE, Date) %>%
summarise(montant = sum(montant))
conversion <- data.frame(
departement = unique(France$departement),
NUTS_CODE = c("FRK", "FRC", "FRH", "FRB", "FRM",
"FRF", "FRE", "FR1", "FRD", "FRI",
"FRJ", "FRG", "FRL", "FRY", "FRY",
"FRY", "FRY", "FRY", "FRY", "FRY"))
write.csv(conversion, "../Data/conversion.csv")
#Grand Est est Alsace-Champagne-Ardenne-Lorraine est FRF
#Hauts-de-France est Nord-pas-de-Calais-Picardy est FRE
#Occitanie est LANGUEDOC-ROUSSILLON-MIDI-PYRÉNÉES est FRJ
France <- France %>%
merge(conversion) %>%
group_by(NUTS_CODE, Date) %>%
summarise(montant = sum(montant))
write.csv(Netherlands, "../Data/Shiny_nl.csv")
write.csv(Belgium, "../Data/Shiny_be.csv")
write.csv(France, "../Data/Shiny_fr.csv")
countries <- list(Netherlands, Belgium, France) %>%
lapply(filter, Date == datum)
Netherlands <- countries[[1]]
Belgium <- countries[[2]]
France <- countries[[3]]
#La fusion de France et des Pays-Bas
Europe <- readOGR(layer = "NUTS_RG_03M_2016_3035_LEVL_1",
dsn = "../Data")
Europe <- sp::merge(Europe, Netherlands, by.x = "NUTS_ID", by.y = "NUTS")
Europe <- sp::merge(Europe, France, by.x = "NUTS_ID", by.y = "NUTS_CODE")
Europe@data <- Europe@data %>%
mutate(montant = ifelse(is.na(montant.x), montant.y, montant.x)) %>%
select(-montant.x, -montant.y)
#Ajouter la Belgique
Europe <- sp::merge(Europe, Belgium, by.x = "NUTS_ID", by.y = "NUTS_CODE")
Europe@data <- Europe@data %>%
mutate(montant = ifelse(is.na(montant.x), montant.y, montant.x)) %>%
select(-montant.x, -montant.y)
m1 <- tm_shape(Europe) + tm_polygons(col = "montant",
palette = "viridis",
showNA = FALSE,
breaks = c(0,50,100,200,500,1000,Inf))
m2 <- tmap_leaflet(m1)
setView(m2, 4.8945, 52.3667, zoom = 5)
library(readxl)
library(rvest)
library(tidyverse)
library(fuzzyjoin)
library(magrittr)
library(leaflet)
library(lubridate)
library(glogis)
library(gridExtra)
library(kableExtra)
x <- c("ggmap", "rgdal", "rgeos", "maptools", "tmap")
lapply(x, library, character.only = TRUE)
#Ici, il faut choisir la data à laquelle on va construire la carte.
datum <- Sys.Date() -1
#Importer les données françaises via cet URL:
France <- read.csv("https://www.data.gouv.fr/fr/datasets/r/fa9b8fc8-35d5-4e24-90eb-9abe586b0fa5",header = TRUE, check.names = F)
France <- France %>%
pivot_longer(2:ncol(France),
names_to = "departement",
values_to = "montant") %>%
mutate(Date = ymd(Date))
write.csv(France, "../Data/France.csv")
Belgium <- read_html("https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Belgium") %>%
html_nodes(".wikitable") %>%
html_table(fill = TRUE) %>%
data.frame() %>%
select(1,3,5,7)
a <- as.numeric(nrow(Belgium))
Belgium <- Belgium[-c(1,(a),(a-1)),] %>%
mutate(Date = ymd(Date))
colnames(Belgium) <- c("Date", "BE2", "BE1", "BE3")
Belgium <- Belgium %>%
pivot_longer(2:4, names_to = "NUTS_CODE", values_to = "montant")
write.csv(Belgium, "../Data/Belgique.csv")
#Importer les données néerlandaises va un peu plus difficilement: on va garder la date dans une colonne séparée:
Netherlands <- read_html("https://www.rivm.nl/coronavirus-kaart-van-nederland") %>%
html_nodes("#csvData") %>%
html_text() %>%
read_lines() %>%
str_split(";") %>%
unlist()
Netherlands <- Netherlands[-1] %>%
matrix(ncol = 5, byrow = TRUE)
Netherlands <- Netherlands[-(1:2),] %>%
as.data.frame()
date <- read_html("https://www.rivm.nl/coronavirus-kaart-van-nederland") %>%
html_nodes('.with-background > p:nth-child(2)') %>%
html_text() %>%
str_extract("[0-9]{2}\\s[a-z]{1,}\\s[0-9]{4}")
colnames(Netherlands) <- c("numero", "municipalite", "montant", "habitants", "montantparhabitant")
Netherlands <- data.frame(Netherlands, Date = date) %>%
filter(municipalite != "")
write.csv(Netherlands, file = paste("../Data/","netherlands_",date,".csv", sep = ""))
files <- list.files("../Data")
files <- files[grepl("netherlands(.+)", files)]
key <- NULL
Netherlands <- NULL
for (i in files) {
key <- read.csv(paste("../Data/",i, sep = "")) %>%
select(-1)
Netherlands <- rbind(Netherlands, key)
}
Before <- read_excel("../Data/corona_04032020tm16032020.xlsx", sheet = 2)
Before <- Before[!is.na(Before$Gemnr),] %>%
pivot_longer(3:ncol(Before), names_to = "Date", values_to = "montant") %>%
mutate(Date = dmy(str_replace(Date, "Aantal", "")))
colnames(Before) <- c("numero", "municipalite", "Date", "montant")
#Municipalites par province
municipalites <- read_html("https://www.metatopos.eu/Gemtab.php") %>%
html_nodes("section.dikkerand:nth-child(3) > article:nth-child(1) > table:nth-child(2)") %>%
html_table(fill = TRUE, header = TRUE) %>%
data.frame()
#municipalites par nl1 nl2 nl3 nl4
NL1 <- read_html("https://www.regioatlas.nl/indelingen/indelingen_indeling/t/nuts_1_regio_s_landsdelen") %>%
html_nodes("#noord_nederland > div:nth-child(3) > ul:nth-child(2)") %>%
html_text(trim = TRUE) %>%
read_lines() %>%
str_replace_all("\t[\\s]{0,}","")
NL2 <- read_html("https://www.regioatlas.nl/indelingen/indelingen_indeling/t/nuts_1_regio_s_landsdelen") %>%
html_nodes("#oost_nederland > div:nth-child(3) > ul:nth-child(2)") %>%
html_text(trim = TRUE) %>%
read_lines() %>%
str_replace_all("\t[\\s]{0,}","")
NL3 <- read_html("https://www.regioatlas.nl/indelingen/indelingen_indeling/t/nuts_1_regio_s_landsdelen") %>%
html_nodes("#west_nederland > div:nth-child(3) > ul:nth-child(2)") %>%
html_text(trim = TRUE) %>%
read_lines() %>%
str_replace_all("\t[\\s]{0,}","")
NL4 <- read_html("https://www.regioatlas.nl/indelingen/indelingen_indeling/t/nuts_1_regio_s_landsdelen") %>%
html_nodes("#zuid_nederland > div:nth-child(3) > ul:nth-child(2)") %>%
html_text(trim = TRUE) %>%
read_lines() %>%
str_replace_all("\t[\\s]{0,}","")
NUTSlvl1 <-
rbind(
data.frame(municipalite = NL1, NUTS = "NL1"),
data.frame(municipalite = NL2, NUTS = "NL2"),
data.frame(municipalite = NL3, NUTS = "NL3"),
data.frame(municipalite = NL4, NUTS = "NL4")
)
Netherlands <- merge(Netherlands, NUTSlvl1)
Netherlands <- Netherlands %>%
group_by(NUTS, Date) %>%
summarise(montant = sum(montant)) %>%
mutate(Date = dmy(Date))
Before <- Before %>%
merge(NUTSlvl1) %>%
mutate(montant = as.numeric(montant)) %>%
group_by(NUTS, Date) %>%
summarise(montant = sum(montant))
Netherlands <- rbind(Netherlands, Before)
Belgium <- Belgium %>%
mutate(montant = as.numeric(montant)) %>%
group_by(NUTS_CODE, Date) %>%
summarise(montant = sum(montant))
conversion <- data.frame(
departement = unique(France$departement),
NUTS_CODE = c("FRK", "FRC", "FRH", "FRB", "FRM",
"FRF", "FRE", "FR1", "FRD", "FRI",
"FRJ", "FRG", "FRL", "FRY", "FRY",
"FRY", "FRY", "FRY", "FRY", "FRY"))
write.csv(conversion, "../Data/conversion.csv")
#Grand Est est Alsace-Champagne-Ardenne-Lorraine est FRF
#Hauts-de-France est Nord-pas-de-Calais-Picardy est FRE
#Occitanie est LANGUEDOC-ROUSSILLON-MIDI-PYRÉNÉES est FRJ
France <- France %>%
merge(conversion) %>%
group_by(NUTS_CODE, Date) %>%
summarise(montant = sum(montant))
write.csv(Netherlands, "../Data/Shiny_nl.csv")
write.csv(Belgium, "../Data/Shiny_be.csv")
write.csv(France, "../Data/Shiny_fr.csv")
countries <- list(Netherlands, Belgium, France) %>%
lapply(filter, Date == datum)
Netherlands <- countries[[1]]
Belgium <- countries[[2]]
France <- countries[[3]]
#La fusion de France et des Pays-Bas
Europe <- readOGR(layer = "NUTS_RG_03M_2016_3035_LEVL_1",
dsn = "../Data")
Europe <- sp::merge(Europe, Netherlands, by.x = "NUTS_ID", by.y = "NUTS")
Europe <- sp::merge(Europe, France, by.x = "NUTS_ID", by.y = "NUTS_CODE")
Europe@data <- Europe@data %>%
mutate(montant = ifelse(is.na(montant.x), montant.y, montant.x)) %>%
select(-montant.x, -montant.y)
#Ajouter la Belgique
Europe <- sp::merge(Europe, Belgium, by.x = "NUTS_ID", by.y = "NUTS_CODE")
Europe@data <- Europe@data %>%
mutate(montant = ifelse(is.na(montant.x), montant.y, montant.x)) %>%
select(-montant.x, -montant.y)
m1 <- tm_shape(Europe) + tm_polygons(col = "montant",
palette = "viridis",
showNA = FALSE,
breaks = c(0,50,100,200,500,1000,Inf))
m2 <- tmap_leaflet(m1)
setView(m2, 4.8945, 52.3667, zoom = 5)
read_html("https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table") %>%
html_nodes("table.wikitable:nth-child(11)") %>%
html_table(fill = TRUE)
library(rvest)
library(dplyr)
read_html("https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table") %>%
html_nodes("table.wikitable:nth-child(11)") %>%
html_table(fill = TRUE)
olympicgames <- read_html("https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table") %>%
html_nodes("table.wikitable:nth-child(11)") %>%
html_table(fill = TRUE)
olympicgames <- read_html("https://en.wikipedia.org/wiki/All-time_Olympic_Games_medal_table") %>%
html_nodes("table.wikitable:nth-child(11)") %>%
html_table(fill = TRUE) %>%
as.data.frame()
View(olympicgames)
summer <- olympicgames[,1:6]
winter <- olympicgames[,c(1,7:11)]
View(summer)
colnames(summer) <- c("Team", "ID", "Gold", "Silver", "Bronze","Total")
summer <- olympicgames[-1,1:6]
View(summer)
colnames(summer) <- c("Team", "ID", "Gold", "Silver", "Bronze","Total")
library(stringr)
library(tidyverse)
?separate
summer %>%
separate(Team, into = c("Country", "Short"), sep = "(")
summer %>%
separate(Team, into = c("Country", "Short"), sep = "\\(")
summer %>%
separate(Team, into = c("Country", "Short"), sep = "\\s\\(", )
summer %>%
separate(Team, into = c("Country", "Short"), sep = "\\s\\(", )
summer <- summer %>%
separate(Team, into = c("Country", "Short"), sep = "\\s\\(", )
View(summer)
summer <- summer %>%
separate(Team, into = c("Country", "Short"), sep = "\\s\\(", ) %>%
mutate(Short = str_extract(Short,"[A-Z]{3}"))
summer <- olympicgames[-1,1:6]
colnames(summer) <- c("Team", "ID", "Gold", "Silver", "Bronze","Total")
summer <- summer %>%
separate(Team, into = c("Country", "Short"), sep = "\\s\\(", ) %>%
mutate(Short = str_extract(Short,"[A-Z]{3}"))
View(summer)
winter <- olympicgames[-1,c(1,7:11)]
View(winter)
colnames(winter) <- c("Team", "ID", "Gold", "Silver", "Bronze","Total")
View(winter)
winter <- winter %>%
separate(Team, into = c("Country", "Short"), sep = "\\s\\(", ) %>%
mutate(Short = str_extract(Short,"[A-Z]{3}"))
View(winter)
winter <- winter[-nrow(winter),]
View(winter)
summer <- summer[-nrow(summer),]
View(summer)
write.csv(summer, "olympicgames_summer.csv")
write.csv(winter, "olympicgames_winter.csv")
getwd()
library(rvest)
library(tidyverse)
library(stringr)
read_html("https://en.wikipedia.org/wiki/Press_Freedom_Index#Worldwide_Press_Freedom_Index") %>%
html_nodes("table.wikitable:nth-child(15)") %>%
html_table(fill = TRUE)
pfi <- read_html("https://en.wikipedia.org/wiki/Press_Freedom_Index#Worldwide_Press_Freedom_Index") %>%
html_nodes("table.wikitable:nth-child(15)") %>%
html_table(fill = TRUE)
clean_names(pfi)
library(janitor)
clean_names(pfi)
pfi <- read_html("https://en.wikipedia.org/wiki/Press_Freedom_Index#Worldwide_Press_Freedom_Index") %>%
html_nodes("table.wikitable:nth-child(15)") %>%
html_table(fill = TRUE) %>%
as.data.frame()
clean_names(pfi)
colnames(pfi)
pfi <- read_html("https://en.wikipedia.org/wiki/Press_Freedom_Index#Worldwide_Press_Freedom_Index") %>%
html_nodes("table.wikitable:nth-child(15)") %>%
html_table(fill = TRUE) %>%
as.data.frame()
colnames(pfi)
View(pfi)
str_extract("[0-9]{4})
str_extract("[0-9]{4}")
names(pfi) %>%
str_extract("[0-9]{4}")
names(pfi[-1]) %>%
str_extract("[0-9]{4}")
colnames(pfi)
colnames(pfi) <- c("Country", names(pfi[-1]) %>%
str_extract("[0-9]{4}"))
View(pfi)
pfi %>%
pivot_longer(-1, names_to = "year", values_to = "value")
pfi %>%
pivot_longer(-1, names_to = "year", values_to = "value") %>%
mutate(rank = str_extract(value, "\\((.+)\\)"))
pfi %>%
pivot_longer(-1, names_to = "year", values_to = "value") %>%
mutate(rank = str_extract(value, "\\((.+)\\)"), value = str_replace(value, "\\((.+)\\)", ""))
pfi %>%
pivot_longer(-1, names_to = "year", values_to = "value") %>%
mutate(rank = str_extract(value, "\\((.+)\\)"), value = str_replace(value, "\\((.+)\\)", "")) %>%
mutate(rank = str_extract(rank, [0-9]{3}))
pfi %>%
pivot_longer(-1, names_to = "year", values_to = "value") %>%
mutate(rank = str_extract(value, "\\((.+)\\)"), value = str_replace(value, "\\((.+)\\)", "")) %>%
mutate(rank = str_extract(rank,"[0-9]{3}"))
pfi %>%
pivot_longer(-1, names_to = "year", values_to = "value") %>%
mutate(rank = str_extract(value, "\\((.+)\\)"), value = str_replace(value, "\\((.+)\\)", "")) %>%
mutate(rank = as.numeric(str_extract(rank,"[0-9]{3}")))
pfi %>%
pivot_longer(-1, names_to = "year", values_to = "value") %>%
mutate(rank = str_extract(value, "\\((.+)\\)"), value = str_replace(value, "\\((.+)\\)", "")) %>%
mutate(rank = as.numeric(str_extract(rank,"[0-9]{3}")))
pfi <- pfi %>%
pivot_longer(-1, names_to = "year", values_to = "value") %>%
mutate(rank = str_extract(value, "\\((.+)\\)"), value = str_replace(value, "\\((.+)\\)", "")) %>%
mutate(rank = as.numeric(str_extract(rank,"[0-9]{3}")))
View(pfi)
pfi <- pfi %>%
pivot_longer(-1, names_to = "year", values_to = "value") %>%
mutate(rank = str_extract(value, "\\((.+)\\)"), value = str_replace(value, "\\((.+)\\)", "")) %>%
mutate(rank = as.numeric(str_extract(rank,"[0-9]{3}")), value = as.numeric(value))
View(pfi)
pfi <- pfi %>%
pivot_longer(-1, names_to = "year", values_to = "value") %>%
mutate(rank = str_extract(value, "\\((.+)\\)"), value = str_replace(value, "\\((.+)\\)", "")) %>%
mutate(rank = as.numeric(str_extract(rank,"[0-9]{3}")))
pfi <- read_html("https://en.wikipedia.org/wiki/Press_Freedom_Index#Worldwide_Press_Freedom_Index") %>%
html_nodes("table.wikitable:nth-child(15)") %>%
html_table(fill = TRUE) %>%
as.data.frame()
colnames(pfi) <- c("Country", names(pfi[-1]) %>%
str_extract("[0-9]{4}"))
pfi <- pfi %>%
pivot_longer(-1, names_to = "year", values_to = "value") %>%
mutate(rank = str_extract(value, "\\((.+)\\)"), value = str_replace(value, "\\((.+)\\)", "")) %>%
mutate(rank = as.numeric(str_extract(rank,"[0-9]{3}")), value = as.numeric(value))
View(pfi)
write.csv(pfi, "worldpressfreedom.csv")
setwd("/home/bas/Documents/Miscprojects/datasetsBQ")
read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv")
Confirmed <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv")
Deaths <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv")
Recovered <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv")
View(Recovered)
Corona <- list(Confirmed, Deaths, Recovered)
View(Confirmed)
library(tidyverse)
library(stringr)
lapply(Corona, pivot_longer(-(1:4), names_to = "date", values_to = "value")
lapply(Corona, pivot_longer, -(1:4), names_to = "date", values_to = "value")
Corona %>%
lapply(pivot_longer, -(1:4), names_to = "date", values_to = "value")
library(lubridate)
Corona %>%
lapply(pivot_longer, -(1:4), names_to = "date", values_to = "value") %>%
lapply(mutate, date = mdy(str_replace(date, "X","")))
Corona %>%
lapply(pivot_longer, -(1:4), names_to = "date", values_to = "value") %>%
lapply(mutate, date = mdy(str_replace(date, "X",""))) %>%
group_by(Country.Region, date) %>%
summarise(value = sum(value))
lapply(summarise(value = sum(value))
Corona %>%
lapply(pivot_longer, -(1:4), names_to = "date", values_to = "value") %>%
lapply(mutate, date = mdy(str_replace(date, "X","")))
Corona <- list(Confirmed, Deaths, Recovered)
Corona %>%
lapply(pivot_longer, -(1:4), names_to = "date", values_to = "value") %>%
lapply(mutate, date = mdy(str_replace(date, "X","")))
Corona <- Corona %>%
lapply(pivot_longer, -(1:4), names_to = "date", values_to = "value") %>%
lapply(mutate, date = mdy(str_replace(date, "X","")))
Recovered <- Corona[[3]]
Confirmed <- Corona[[1]]
Deaths <- Corona[[2]]
View(Confirmed)
Confirmed %>%
group_by(Country.Region, date) %>%
summarise(value = sum(value))
Confirmed <- Confirmed %>%
group_by(Country.Region, date) %>%
summarise(value = sum(value))
Deaths <- Deaths %>%
group_by(Country.Region, date) %>%
summarise(value = sum(value))
Recovered <- Recovered %>%
group_by(Country.Region, date) %>%
summarise(value = sum(value))
View(Deaths)
merge(Confirmed, Deaths, by = c("Country.Region", "date"))
Corona <- merge(Confirmed, Deaths, by = c("Country.Region", "date"))
colnames(Corona)[3:4] <- c("Confirmed", "Deaths")
View(Confirmed)
View(Corona)
merge(Corona, Recovered, by = c("Country.Region", "date"))
Corona <- merge(Corona, Recovered, by = c("Country.Region", "date"))
colnames(Corona)[5] <- "Recovered"
write.csv(Corona, "coronavirusdata.csv")
View(Corona)
